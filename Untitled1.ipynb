{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дз 1, Николич Стефан"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Выберите произвольный достаточно длиный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Я выбрал этот - http://www.alleng.ru/d/hist_vm/hist053.htm\n",
    "# Положим его в string переменную \n",
    "with open('text.txt', 'r') as myfile:\n",
    "    text = myfile.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ВВЕДЕНИЕ200 тысяч лет назад человекообразное существо, известное под именем Homo erectus (Человек пр'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример отрывка\n",
    "text[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ВВЕДЕНИЕ', 'тысяч', 'лет', 'назад', 'человекообразное']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Уберем все небуквенные символы\n",
    "regex = re.compile('[^а-яА-Я]') # Регулярное выр-ие на все буквенные символы\n",
    "new_text = regex.sub(' ', text).split() # Убираем все не буквенные символы и сегментируем текст на словоформы\n",
    "new_text[0:5] # Небольшой отрывок получившегося"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['введение', 'тысяч', 'лет', 'назад', 'человекообразное']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переведем все буквы в словоформах в нижний регистр\n",
    "for word_index in range(len(new_text)):\n",
    "    new_text[word_index] = new_text[word_index].lower()\n",
    "new_text[0:5] # Небольшой отрывок получившегося"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Найдите 20 самых частотных словоформ и лемм со стоп-словами и без стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в 6539\n",
      "и 4402\n",
      "что 2852\n",
      "на 1914\n",
      "с 1480\n",
      "не 1423\n",
      "это 1301\n",
      "как 1276\n",
      "из 1007\n",
      "до 887\n",
      "то 866\n",
      "о 863\n",
      "по 851\n",
      "к 813\n",
      "но 782\n",
      "было 723\n",
      "был 702\n",
      "а 696\n",
      "лет 665\n",
      "его 620\n"
     ]
    }
   ],
   "source": [
    "# Находим 20 самых частотных словоформ учитывая стоп-слова и без лемматизации\n",
    "# Используем NLTK\n",
    "import nltk\n",
    "fdist = nltk.FreqDist(new_text) # creates a frequency distribution from a list\n",
    "for word, count in fdist.most_common(20):\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это 1301\n",
      "в 799\n",
      "лет 665\n",
      "рх 501\n",
      "что 492\n",
      "богов 446\n",
      "не 430\n",
      "время 423\n",
      "году 408\n",
      "образом 353\n",
      "том 344\n",
      "также 341\n",
      "и 308\n",
      "как 299\n",
      "таким 266\n",
      "то 264\n",
      "которые 262\n",
      "же 258\n",
      "этих 242\n",
      "пирамиды 226\n"
     ]
    }
   ],
   "source": [
    "# Теперь делаем тоже самое уже без стоп-слов и без лемматизации\n",
    "\n",
    "# Стоп-слова достаем из библиотеки NLTK\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# Теперь убираем их из нашего текста\n",
    "for word in new_text:\n",
    "    if word in stop_words:\n",
    "        new_text.remove(word)\n",
    "\n",
    "# Выдаем топ-20 без стоп-слов\n",
    "fdist = nltk.FreqDist(new_text) # creates a frequency distribution from a list\n",
    "for word, count in fdist.most_common(20):\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это 1648\n",
      "год 1511\n",
      "который 1225\n",
      "бог 1225\n",
      "в 836\n",
      "тот 807\n",
      "этот 791\n",
      "такой 746\n",
      "время 732\n",
      "один 701\n",
      "быть 597\n",
      "мочь 579\n",
      "человек 540\n",
      "что 515\n",
      "рх 501\n",
      "свой 491\n",
      "земля 489\n",
      "пирамида 482\n",
      "он 474\n",
      "они 441\n"
     ]
    }
   ],
   "source": [
    "# Лемматизируем все словоформы в тексте с помощью pymorphy\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()\n",
    "\n",
    "# Лемматизация\n",
    "for word_index in range(len(new_text)):\n",
    "    new_text[word_index] = m.parse(new_text[word_index])[0].normal_form\n",
    "\n",
    "# Топ-20 словоформ с учетом лемматизации и без стоп-слов\n",
    "fdist = nltk.FreqDist(new_text) # creates a frequency distribution from a list\n",
    "for word, count in fdist.most_common(20):\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в 6796\n",
      "и 4402\n",
      "что 2888\n",
      "быть 2786\n",
      "на 1914\n",
      "это 1858\n",
      "с 1616\n",
      "год 1511\n",
      "этот 1432\n",
      "не 1423\n",
      "он 1359\n",
      "как 1276\n",
      "который 1225\n",
      "бог 1225\n",
      "тот 1141\n",
      "они 1107\n",
      "из 1009\n",
      "о 1007\n",
      "мы 897\n",
      "до 887\n"
     ]
    }
   ],
   "source": [
    "# Осталось получить топ-20 словоформ учитывая стоп-слова и лемматизацию\n",
    "# я уже поменял текст(убрав стоп-слова), поэтому загружу его снова\n",
    "# т.е. скомпилирую заново все что было до 2го задания, и получу в переменную new_text что надо \n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "m = MorphAnalyzer()\n",
    "\n",
    "# Лемматизация\n",
    "for word_index in range(len(new_text)):\n",
    "    new_text[word_index] = m.parse(new_text[word_index])[0].normal_form\n",
    "\n",
    "# Топ-20 словоформ с учетом лемматизации и УЧИТЫВАЯ стоп-слова\n",
    "fdist = nltk.FreqDist(new_text) # creates a frequency distribution from a list\n",
    "for word, count in fdist.most_common(20):\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Найдите пример, в котором pymorphy «выиграет» у mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In text:  превратилось\n",
      "pymorphy:  превратиться\n",
      "mystem:  превращаться\n",
      "--------\n",
      "In text:  объем\n",
      "pymorphy:  объесть\n",
      "mystem:  объем\n",
      "--------\n",
      "In text:  увеличился\n",
      "pymorphy:  увеличиться\n",
      "mystem:  увеличиваться\n",
      "--------\n",
      "In text:  обрел\n",
      "pymorphy:  обрести\n",
      "mystem:  обретать\n",
      "--------\n",
      "In text:  приблизилось\n",
      "pymorphy:  приблизиться\n",
      "mystem:  приближаться\n",
      "--------\n",
      "In text:  произойти\n",
      "pymorphy:  произойти\n",
      "mystem:  происходить\n",
      "--------\n",
      "In text:  ученых\n",
      "pymorphy:  учёный\n",
      "mystem:  ученый\n",
      "--------\n",
      "In text:  хомски\n",
      "pymorphy:  хомск\n",
      "mystem:  хомский\n",
      "--------\n",
      "In text:  том\n",
      "pymorphy:  тот\n",
      "mystem:  том\n",
      "--------\n",
      "In text:  может\n",
      "pymorphy:  мочь\n",
      "mystem:  может\n",
      "--------\n",
      "In text:  всерьез\n",
      "pymorphy:  всерьёз\n",
      "mystem:  всерьез\n",
      "--------\n",
      "In text:  может\n",
      "pymorphy:  мочь\n",
      "mystem:  может\n",
      "--------\n",
      "In text:  объяснить\n",
      "pymorphy:  объяснить\n",
      "mystem:  объяснять\n",
      "--------\n",
      "In text:  все\n",
      "pymorphy:  весь\n",
      "mystem:  все\n",
      "--------\n",
      "In text:  больше\n",
      "pymorphy:  большой\n",
      "mystem:  больше\n",
      "--------\n",
      "In text:  посвященных\n",
      "pymorphy:  посвятить\n",
      "mystem:  посвящать\n",
      "--------\n",
      "In text:  вызвавших\n",
      "pymorphy:  вызвать\n",
      "mystem:  вызывать\n",
      "--------\n",
      "In text:  гизы\n",
      "pymorphy:  гиза\n",
      "mystem:  гиз\n",
      "--------\n",
      "In text:  отнесенного\n",
      "pymorphy:  отнести\n",
      "mystem:  относить\n",
      "--------\n",
      "In text:  во\n",
      "pymorphy:  в\n",
      "mystem:  во\n",
      "--------\n",
      "In text:  всех\n",
      "pymorphy:  весь\n",
      "mystem:  все\n",
      "--------\n",
      "In text:  наска\n",
      "pymorphy:  наск\n",
      "mystem:  наско\n",
      "--------\n",
      "In text:  окутанной\n",
      "pymorphy:  окутать\n",
      "mystem:  окутывать\n",
      "--------\n",
      "In text:  признать\n",
      "pymorphy:  признать\n",
      "mystem:  признавать\n",
      "--------\n",
      "In text:  ухватиться\n",
      "pymorphy:  ухватиться\n",
      "mystem:  ухватываться\n",
      "--------\n",
      "In text:  извинить\n",
      "pymorphy:  извинить\n",
      "mystem:  извинять\n",
      "--------\n",
      "In text:  продвинутые\n",
      "pymorphy:  продвинуть\n",
      "mystem:  продвигать\n",
      "--------\n",
      "In text:  проследить\n",
      "pymorphy:  проследить\n",
      "mystem:  прослеживать\n",
      "--------\n",
      "In text:  еще\n",
      "pymorphy:  ещё\n",
      "mystem:  еще\n",
      "--------\n",
      "In text:  первой\n",
      "pymorphy:  один\n",
      "mystem:  первый\n",
      "--------\n",
      "In text:  возникшей\n",
      "pymorphy:  возникнуть\n",
      "mystem:  возникать\n",
      "--------\n",
      "In text:  им\n",
      "pymorphy:  имя\n",
      "mystem:  они\n",
      "--------\n",
      "In text:  все\n",
      "pymorphy:  весь\n",
      "mystem:  все\n",
      "--------\n",
      "In text:  может\n",
      "pymorphy:  мочь\n",
      "mystem:  может\n",
      "--------\n",
      "In text:  месопотамии\n",
      "pymorphy:  месопотамия\n",
      "mystem:  месопотамий\n",
      "--------\n",
      "In text:  найденные\n",
      "pymorphy:  найти\n",
      "mystem:  находить\n",
      "--------\n",
      "In text:  переведенные\n",
      "pymorphy:  перевести\n",
      "mystem:  переводить\n",
      "--------\n",
      "In text:  подогнано\n",
      "pymorphy:  подогнать\n",
      "mystem:  подгонять\n",
      "--------\n",
      "In text:  посвящена\n",
      "pymorphy:  посвятить\n",
      "mystem:  посвящать\n",
      "--------\n",
      "In text:  тем\n",
      "pymorphy:  тем\n",
      "mystem:  то\n",
      "--------\n",
      "In text:  чем\n",
      "pymorphy:  чем\n",
      "mystem:  что\n",
      "--------\n",
      "In text:  неудивительно\n",
      "pymorphy:  неудивительно\n",
      "mystem:  неудивительный\n",
      "--------\n",
      "In text:  во\n",
      "pymorphy:  в\n",
      "mystem:  во\n",
      "--------\n",
      "In text:  отчетах\n",
      "pymorphy:  отчёт\n",
      "mystem:  отчет\n",
      "--------\n",
      "In text:  полученных\n",
      "pymorphy:  получить\n",
      "mystem:  получать\n",
      "--------\n",
      "In text:  вторых\n",
      "pymorphy:  второе\n",
      "mystem:  второй\n",
      "--------\n",
      "In text:  тому\n",
      "pymorphy:  тот\n",
      "mystem:  то\n",
      "--------\n",
      "In text:  изучить\n",
      "pymorphy:  изучить\n",
      "mystem:  изучать\n",
      "--------\n",
      "In text:  собрать\n",
      "pymorphy:  собрать\n",
      "mystem:  собирать\n",
      "--------\n",
      "In text:  получилась\n",
      "pymorphy:  получиться\n",
      "mystem:  получаться\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "# Опять же скомпилируем все до первого пункта, чтобы получить new_text без лемматизации и убирании stop_words\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "m1 = MorphAnalyzer()\n",
    "m2 = Mystem()\n",
    "\n",
    "# Ищем пример\n",
    "count = 0\n",
    "for word in new_text:\n",
    "    if m1.parse(word)[0].normal_form != m2.lemmatize(word)[0]:\n",
    "        print(\"In text: \", word)\n",
    "        print(\"pymorphy: \", m1.parse(word)[0].normal_form)\n",
    "        print(\"mystem: \", m2.lemmatize(word)[0])\n",
    "        print(\"--------\")\n",
    "        count += 1\n",
    "        if count >= 50:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый очевидный пример \"победы\" pymorphy среди полученных примеров:\n",
    "\n",
    "In text:  месопотамии\n",
    "\n",
    "\n",
    "pymorphy:  месопотамия\n",
    "\n",
    "\n",
    "mystem:  месопотамий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Найдите осмысленные синонимы в тексте, а также слова с общим контекстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обрабатываем сырой текст в NLTK\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "nltk_text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "создан расположен сотворен начат основан воздвигнут восстановлен вырыт\n",
      "либо смешан подготовлен инструмент достигнут рассчитан внезапно\n",
      "известен лет разрушен последним найден\n"
     ]
    }
   ],
   "source": [
    "# Осмысленные синонимы\n",
    "nltk_text.similar(\"построен\") # по-началу синонимы адекватны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "что_было\n"
     ]
    }
   ],
   "source": [
    "# Слова с общим контекстом\n",
    "nltk_text.common_contexts([\"это\", \"лет\"]) # с трудом подобралось"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
